{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import random\n","from torch.utils.data import DataLoader,TensorDataset\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","class AugmentedDatasetSTEAD(torch.utils.data.Dataset):\n","    def __init__(self,\n","                  path =\"STEAD_data/chunk2/\",\n","                  predict_pga = False,\n","                  data_percent = 1,\n","                    *args, **kwargs\n","                  ):\n","        super(AugmentedDatasetSTEAD, self).__init__()\n","\n","        self.path = path\n","        self.predict_pga = predict_pga\n","        self.broadband_dataset         = torch.load(self.path + \"chunk2_acceleration.pt\")\n","        self.fc                        = torch.load(self.path + \"chunk2_fc.pt\")\n","        #self.meta_data_depth           = torch.load(self.path + \"meta_data_depth.pt\")   # NON SO SE LI VOGLIAMO METTERE\n","        #self.meta_data_magnitude       = torch.load(self.path + \"meta_data_magnitude.pt\")\n","        self.data_percent = data_percent\n","\n","    def __len__(self):\n","        return int(self.data_percent*len(self.broadband_dataset))\n","\n","    def __getitem__(self,index):\n","        broadband   = self.broadband_dataset[index,:,:].float()\n","        fc          = self.fc[index,None].float()\n","        # depth       = self.meta_data_depth[index].float()\n","        # magnitude   = self.meta_data_magnitude[index].float()\n","\n","\n","\n","        true_pga,_ = torch.max(torch.abs(broadband),dim = 1)\n","        # Normalize broadband and lowpass\n","        if not self.predict_pga:\n","            broadband = broadband / true_pga[:,None]\n","        return broadband, fc, true_pga # depth, magnitude\n","\n","\n","\n","class AugmentedDataModule :\n","    def __init__(self,\n","                 batch_size  = 64,\n","                 num_workers = 4,\n","                 path = \"STEAD_data/chunk2/\",\n","                 predict_pga = False,\n","                 seed = 42,\n","                 *args, **kwargs\n","                 ) -> None:\n","\n","        if path == \"data/nsy51200/temporary/\":\n","            self.ds = AugmentedDataset(path)\n","        else :\n","            self.ds = AugmentedDatasetSTEAD(path, predict_pga = predict_pga)\n","\n","        self.batch_size = batch_size\n","        self.num_workers = num_workers\n","        self.seed = seed\n","        self.set_seed(seed)\n","\n","    def set_seed(self, seed_value=42):\n","        \"\"\"Set seed for reproducibility.\"\"\"\n","        random.seed(seed_value)  # Python random module\n","        np.random.seed(seed_value)  # Numpy module\n","        torch.manual_seed(seed_value)  # PyTorch\n","        torch.cuda.manual_seed_all(seed_value)  # For multi-GPU setups\n","\n","    def define_dataset(self):\n","        train_partition, valid_partition = int(0.80*len(self.ds)), int(0.10*len(self.ds))\n","        test_partition = len(self.ds) - train_partition - valid_partition\n","        generator = torch.Generator().manual_seed(self.seed)\n","        self.train_ds, self.valid_ds, self.test_ds = torch.utils.data.random_split(\n","            self.ds, [train_partition, valid_partition, test_partition], generator=generator)\n","\n","\n","    def define_dataloader(self):\n","\n","        self.train_loader = DataLoader(\n","            self.train_ds,\n","            batch_size = self.batch_size,\n","            num_workers = self.num_workers\n","\n","        )\n","        self.test_loader = DataLoader(\n","            self.test_ds,\n","            batch_size = self.batch_size,\n","            num_workers = self.num_workers\n","        )\n","\n","        self.valid_loader = DataLoader(\n","            self.valid_ds,\n","            batch_size = self.batch_size,\n","            num_workers = self.num_workers\n","        )\n","        self.combined_loader = DataLoader(\n","            self.ds,\n","            batch_size = self.batch_size,\n","            num_workers = self.num_workers\n","        )\n","\n","        y,x,*other = next(iter(self.train_loader))\n","        self.one_batch = DataLoader(TensorDataset(y,x,*other),\n","                                    batch_size= 1  )\n","\n","    def setup(self):\n","        self.define_dataset()\n","        self.define_dataloader()\n"],"metadata":{"id":"2BaK-cW_jNsO"},"execution_count":null,"outputs":[]}]}