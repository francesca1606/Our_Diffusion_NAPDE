{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOeRRzidviIQwr9nN93je+d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8JRYacS4tkh-"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from diffusion.diffusion_model import DiffusionAttnUnet1DCond\n","\n","# Loading the state_dict of the previosuly-trained model\n","state_dict_old = torch.load(\"trained_models/diffusion_model_original.pth\", map_location=\"cpu\")\n","\n","# Cut the weights not needed for unconditional diffusion\n","for prefix in [\"diffusion.\", \"diffusion_ema.\"]:\n","\n","    weight_main = state_dict_old[f\"{prefix}net.0.main.0.weight\"]  # [128, 22, 5]\n","    bias_main   = state_dict_old[f\"{prefix}net.0.main.0.bias\"]\n","    weight_skip = state_dict_old[f\"{prefix}net.0.skip.weight\"]    # [128, 22, 1]\n","\n","    # New layers of 19 channels\n","    new_main_weight = weight_main[:, :19, :].clone()\n","    new_skip_weight = weight_skip[:, :19, :].clone()\n","\n","    state_dict_old[f\"{prefix}net.0.main.0.weight\"] = new_main_weight\n","    state_dict_old[f\"{prefix}net.0.main.0.bias\"]   = bias_main.clone()\n","    state_dict_old[f\"{prefix}net.0.skip.weight\"]   = new_skip_weight\n","\n","    w_main6 = state_dict_old[f\"{prefix}net.6.main.3.weight\"]  # [6, 128, 5]\n","    b_main6 = state_dict_old[f\"{prefix}net.6.main.3.bias\"]\n","    w_skip6 = state_dict_old[f\"{prefix}net.6.skip.weight\"]    # [6, 128, 1]\n","\n","    state_dict_old[f\"{prefix}net.6.main.3.weight\"] = w_main6[:3].clone()\n","    state_dict_old[f\"{prefix}net.6.main.3.bias\"]   = b_main6[:3].clone()\n","    state_dict_old[f\"{prefix}net.6.skip.weight\"]   = w_skip6[:3].clone()\n","\n","    # lastconv\n","    w_last = state_dict_old[f\"{prefix}lastconv.weight\"]  # [3, 6, 3]\n","    b_last = state_dict_old[f\"{prefix}lastconv.bias\"]\n","\n","    state_dict_old[f\"{prefix}lastconv.weight\"] = w_last[:, :3, :].clone()\n","    state_dict_old[f\"{prefix}lastconv.bias\"]   = b_last.clone()\n","\n","# Updated model\n","torch.save(state_dict_old, \"trained_models/Model_trimmed_NOcond.pth\")\n","\n","print(f\"Total number of keys: {len(state_dict_old)}\")"]}]}